# Notes - Spark Data + AI Summit 2022

Tags: Study

**Unity Catalog: Journey to unified governance for your Data and AI assets on Lakehouse**

- Modern data assets take many forms: not just files or tables, but dashboards, ML models, and unstructured data like video and images, all of which cannot be governed and managed by legacy data governance solutions.
- Use Unity Catalog to centrally manage all data and AI assets with a common governance model based on familiar ANSI SQL, ensuring much better native performance and security.
- Built-in automated data lineage provides end-to-end visibility into how data flows from source to consumption, so that organizations can identify and diagnose the impact of data changes.
- Unity Catalog delivers the flexibility to leverage existing data catalogs and solutions and establish a future-proof, centralized governance without expensive migration costs. It also creates detailed audit reports for data compliance and security, while ensuring data teams can quickly discover and reference data for BI, analytics, and ML workloads, accelerating time to value.
- Advancing Spark - First Look at Unity Catalog - ****[https://www.youtube.com/watch?v=FCuuFGS3jFM](https://www.youtube.com/watch?v=FCuuFGS3jFM)
- Databricks official - [https://www.databricks.com/product/unity-catalog](https://www.databricks.com/product/unity-catalog)
- Metastore
    - is the top-level container for data in Unity Catalog
    - with it, Unity catalog provides a 3-level namespace for organizing the data catalogs
        - Catalog
        - schemas (also called databases)
        - tables/views

---

**Turning Fan Data Into an Asset**

- The sports industry is evolving, with organizations investing heavily into their tech stack. Simply connecting data, however, is not enough. Unexpected insights can come from anyone â€” but only if they have tools they can easily use.
- Pumpjack Dataworks, the worldâ€™s leading fan data refinery. This platform enables clubs, leagues, and sponsors to discover digital revenue channels by joining consumer data while assuring its protection. Powered by Databricksâ€™ Delta Sharing protocol and governed by Immutaâ€™s data access platform, this solution democratizes fan data, making it immediately accessible.
- How automating access control provides scalable, rule-driven assurance that data is properly managed and analyzed.
- How Pumpjack Dataworks uses **attribute-based** access control to meet privacy regulations and data sharing requirements
- How Databricks and Immutaâ€™s partnership enables robust governance
- Why ABAC (attribute based access control) is critical for scale within modern data stacks
- Delta Sharing - The worldâ€™s first open protocol for secure data sharing
    - sharing is easy
        - read only
        - secured
        - multi-cloud and region
        - audited
        - managed
            - tokenless
            - known fixed source and target metastores

![Untitled](Notes%20-%20Spark%20Data%20+%20AI%20Summit%202022%200c28574add5b4528917d031587f50965/Untitled.png)

![Untitled](Notes%20-%20Spark%20Data%20+%20AI%20Summit%202022%200c28574add5b4528917d031587f50965/Untitled%201.png)

---

**The Future of Data - Whatâ€™s Next with Google Cloud**

![Untitled](Notes%20-%20Spark%20Data%20+%20AI%20Summit%202022%200c28574add5b4528917d031587f50965/Untitled%202.png)

- Trends and challenges
    - Multi cloud is becoming the standard with one cloud usually more focused on data use cases
    - Customers need consistent governance and security policies across various compute and storage services
    - An end to end ecosystem for data and AI is more important than any single product
    - Real-time analytics continue to grow in importance
    - Price/Performance is a key metric
    - Data mesh is in most of customerâ€™s agendas

> Data fabric v.s. Data Mesh
> 

([https://www.rtinsights.com/data-fabric-vs-data-mesh-key-differences-and-similarities/#:~:text=The difference between them is,are specific to business domains](https://www.rtinsights.com/data-fabric-vs-data-mesh-key-differences-and-similarities/#:~:text=The%20difference%20between%20them%20is,are%20specific%20to%20business%20domains).)

<aside>
ðŸ’¡ Both are data management architectures

</aside>

<aside>
ðŸ’¡ The difference between them is that data fabric is a framework that is tech agnostic that can deliver data products as one of its many outputs, while data mesh is an architecture that only produces data products that are specific to business domains

</aside>

- Data fabric
    - A data fabric is an architectural approach to simplify data access in an organization to facilitate self-service data consumption. This architecture is agnostic to data environments, processes, utility and geography, all while integrating end-to-end data-management capabilities. A data fabric automates data discovery, governance and consumption, enabling enterprises to use data to maximize their value chain. With a data fabric, enterprises elevate the value of their data by providing the right data, at the right time, regardless of where it resides.
    - A data fabric is an architecture and set of data services that provide consistent capabilities across a choice of endpoints spanning hybrid multi-cloud environments. It is a powerful architecture that standardizes data management practices and practicalities across cloud, on premises, and edge devices. Among the many advantages that a data fabric affords, data visibility and insights, data access and control, data protection, and security quickly rise to the top.
    - [https://www.netapp.com/data-fabric/what-is-data-fabric/](https://www.netapp.com/data-fabric/what-is-data-fabric/)
    - Data fabric is a metadata-driven process at its core, where it aims to connect a wide array of data sources and tools in a united and self-service manner. (Data fabric is essentially a data management process)
    - With data fabric deployed over these repositories, data lakes, or warehouses, it brings about clarity in terms of the **centralization** of data across the organization.
- Data mesh
    - domain specific
    - the self-service Infrastructure-as-a-Platform provides the teams that requisition data along with monitoring, logging, alerting, and standardization â†’ all with a standard process that is the same across the board and which is also domain agnostic
    - both strive to bring organization to the data that is spread across the databases or data lakes, Data fabric is very technology-centric, and data mesh focuses on organizational changes. Mesh depends on people and teams for the change in organizational changes, and the fabric is an architectural approach to handle complex data and metadata.
    - In terms of design, data fabric makes use of the metadata and the centralized data engineering according to the overall experience of the data consumers in the organization, while data mesh uses expertise that the teams have across various domains to create and design its deliverable: a business-oriented data product.

<aside>
ðŸ’¡ They both are architecture frameworks but not architectures. The architecture comes when the needs are properly defined, the data understood, and the processes in the organization accounted for.

</aside>