{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "a\n",
      "n\n",
      "a\n",
      "n\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "fruit = \"banana\"\n",
    "index = 0\n",
    "while index < len(fruit):\n",
    "    letter = fruit[index]\n",
    "    index += 1\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "a\n",
      "n\n",
      "a\n",
      "n\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for i in fruit:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'a', 'n', 'a', 'n', 'a']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in fruit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'a', 'n', 'a', 'n', 'a']\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "result = list()\n",
    "while index < len(fruit):\n",
    "    letter = fruit[index]\n",
    "    index += 1\n",
    "    result.append(letter)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'a', 'n', 'a', 'n', 'a']\n"
     ]
    }
   ],
   "source": [
    "res = list() #create/define new list\n",
    "for i in range(0, len(fruit)):\n",
    "    letter = fruit[i]\n",
    "    res.append(letter)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'a', 'n', 'a', 'n', 'a']\n"
     ]
    }
   ],
   "source": [
    "res = []  #another way to creat/define a new list\n",
    "for i in range(0, len(fruit)):\n",
    "    letter = fruit[i]\n",
    "    res.append(letter)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_minutes_to_pandas.ipynb             \u001b[34mText mining with Python\u001b[m\u001b[m/\r\n",
      "Book_learn Python3 the hard way.ipynb  \u001b[34mUoE_ML Practical Labs_notebooks\u001b[m\u001b[m/\r\n",
      "\u001b[34mData Programming with Python\u001b[m\u001b[m/          \u001b[31mcs228-python-tutorial.ipynb\u001b[m\u001b[m*\r\n",
      "SCRATCH NOTES.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_minutes_to_pandas.ipynb             \u001b[34mText mining with Python\u001b[m\u001b[m/\r\n",
      "Book_learn Python3 the hard way.ipynb  \u001b[34mUoE_ML Practical Labs_notebooks\u001b[m\u001b[m/\r\n",
      "\u001b[34mData Programming with Python\u001b[m\u001b[m/          \u001b[31mcs228-python-tutorial.ipynb\u001b[m\u001b[m*\r\n",
      "SCRATCH NOTES.ipynb                    \u001b[34mdocs\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./docs/test01.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "handle = open('./docs/test01.txt')\n",
    "print(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 2, 'is': 1, 'a': 1, 'test': 1, 'for': 1, 'text': 1, 'in': 1, 'python': 1, 'list': 1, 'and': 1, 'the': 2, 'words': 2, 'are': 3, 'randomly': 1, 'created': 1, 'by': 1, 'me': 1, 'haha,': 1, 'good': 2, 'or': 1, 'not': 1, 'really': 1, 'depend': 1, 'on': 1, 'what': 1, 'you': 2, 'think': 1, 'about': 1, 'it.': 1, 'kidding': 1, 'me,': 1, 'yes': 1, 'i': 1, 'am.': 1, 'so': 1, 'let': 1, 'us': 2, 'just': 1, 'to': 1, 'do': 1, 'test.': 1}\n"
     ]
    }
   ],
   "source": [
    "counts = dict()\n",
    "for line in handle:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this 2\n",
      "is 1\n",
      "a 1\n",
      "test 1\n",
      "for 1\n",
      "text 1\n",
      "in 1\n",
      "python 1\n",
      "list 1\n",
      "and 1\n",
      "the 2\n",
      "words 2\n",
      "are 3\n",
      "randomly 1\n",
      "created 1\n",
      "by 1\n",
      "me 1\n",
      "haha, 1\n",
      "good 2\n",
      "or 1\n",
      "not 1\n",
      "really 1\n",
      "depend 1\n",
      "on 1\n",
      "what 1\n",
      "you 2\n",
      "think 1\n",
      "about 1\n",
      "it. 1\n",
      "kidding 1\n",
      "me, 1\n",
      "yes 1\n",
      "i 1\n",
      "am. 1\n",
      "so 1\n",
      "let 1\n",
      "us 2\n",
      "just 1\n",
      "to 1\n",
      "do 1\n",
      "test. 1\n"
     ]
    }
   ],
   "source": [
    "lst = list()\n",
    "for k,v in counts.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('this', 2), ('is', 1), ('a', 1), ('test', 1), ('for', 1), ('text', 1), ('in', 1), ('python', 1), ('list', 1), ('and', 1), ('the', 2), ('words', 2), ('are', 3), ('randomly', 1), ('created', 1), ('by', 1), ('me', 1), ('haha,', 1), ('good', 2), ('or', 1), ('not', 1), ('really', 1), ('depend', 1), ('on', 1), ('what', 1), ('you', 2), ('think', 1), ('about', 1), ('it.', 1), ('kidding', 1), ('me,', 1), ('yes', 1), ('i', 1), ('am.', 1), ('so', 1), ('let', 1), ('us', 2), ('just', 1), ('to', 1), ('do', 1), ('test.', 1)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'are'), (2, 'you'), (2, 'words'), (2, 'us'), (2, 'this'), (2, 'the'), (2, 'good'), (1, 'yes'), (1, 'what'), (1, 'to'), (1, 'think'), (1, 'text'), (1, 'test.'), (1, 'test'), (1, 'so'), (1, 'really'), (1, 'randomly'), (1, 'python'), (1, 'or'), (1, 'on'), (1, 'not'), (1, 'me,'), (1, 'me'), (1, 'list'), (1, 'let'), (1, 'kidding'), (1, 'just'), (1, 'it.'), (1, 'is'), (1, 'in'), (1, 'i'), (1, 'haha,'), (1, 'for'), (1, 'do'), (1, 'depend'), (1, 'created'), (1, 'by'), (1, 'and'), (1, 'am.'), (1, 'about'), (1, 'a')]\n"
     ]
    }
   ],
   "source": [
    "for k,v in counts.items():\n",
    "    lst.append((v, k))\n",
    "unique_list = set(lst)\n",
    "lst = sorted(unique_list, reverse = True)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us 2\n",
      "you 2\n",
      "this 2\n",
      "words 2\n",
      "are 3\n"
     ]
    }
   ],
   "source": [
    "for v,k in set(lst[:5]):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'are'), (2, 'you'), (2, 'words'), (2, 'us'), (2, 'this'), (2, 'the'), (2, 'good'), (1, 'yes'), (1, 'what'), (1, 'to'), (1, 'think'), (1, 'text'), (1, 'test.'), (1, 'test'), (1, 'so'), (1, 'really'), (1, 'randomly'), (1, 'python'), (1, 'or'), (1, 'on'), (1, 'not'), (1, 'me,'), (1, 'me'), (1, 'list'), (1, 'let'), (1, 'kidding'), (1, 'just'), (1, 'it.'), (1, 'is'), (1, 'in'), (1, 'i'), (1, 'haha,'), (1, 'for'), (1, 'do'), (1, 'depend'), (1, 'created'), (1, 'by'), (1, 'and'), (1, 'am.'), (1, 'about'), (1, 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(sorted([(v,k) for k,v in counts.items()], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us 2\n",
      "you 2\n",
      "this 2\n",
      "words 2\n",
      "are 3\n"
     ]
    }
   ],
   "source": [
    "for v,k in set(lst[:5]):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.arange(3,7,2))  #the last number here is the step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "print(a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2], [3,4]])\n",
    "b = np.array([[5,6]])\n",
    "np.concatenate((a,b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2]\n",
    "print(np.asarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  1]\n",
      " [28  1]]\n"
     ]
    }
   ],
   "source": [
    "x = np.matrix( ((2,3), (3, 5)))\n",
    "y = np.matrix( ((1,2), (5, -1)))\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [15 -5]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array( ((2,3), (3, 5)))\n",
    "y = np.array( ((1,2), (5, -1)))\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  1]\n",
      " [28  1]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array( ((2,3), (3, 5)))\n",
    "y = np.array( ((1,2), (5, -1)))\n",
    "print(np.dot(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3  4\n",
      "0   5.1  3.5  1.4  0.2  1\n",
      "1   4.9  3.0  1.4  0.2  1\n",
      "2   4.7  3.2  1.3  0.2  1\n",
      "3   4.6  3.1  1.5  0.2  1\n",
      "4   5.0  3.6  1.4  0.2  1\n",
      "5   5.4  3.9  1.7  0.4  1\n",
      "6   4.6  3.4  1.4  0.3  1\n",
      "7   5.0  3.4  1.5  0.2  1\n",
      "8   4.4  2.9  1.4  0.2  1\n",
      "9   4.9  3.1  1.5  0.1  1\n",
      "10  5.4  3.7  1.5  0.2  1\n",
      "11  4.8  3.4  1.6  0.2  1\n",
      "12  4.8  3.0  1.4  0.1  1\n",
      "13  4.3  3.0  1.1  0.1  1\n",
      "14  5.8  4.0  1.2  0.2  1\n",
      "15  5.7  4.4  1.5  0.4  1\n",
      "16  5.4  3.9  1.3  0.4  1\n",
      "17  5.1  3.5  1.4  0.3  1\n",
      "18  5.7  3.8  1.7  0.3  1\n",
      "19  5.1  3.8  1.5  0.3  1\n",
      "20  5.4  3.4  1.7  0.2  1\n",
      "21  5.1  3.7  1.5  0.4  1\n",
      "22  4.6  3.6  1.0  0.2  1\n",
      "23  5.1  3.3  1.7  0.5  1\n",
      "24  4.8  3.4  1.9  0.2  1\n",
      "25  5.0  3.0  1.6  0.2  1\n",
      "26  5.0  3.4  1.6  0.4  1\n",
      "27  5.2  3.5  1.5  0.2  1\n",
      "28  5.2  3.4  1.4  0.2  1\n",
      "29  4.7  3.2  1.6  0.2  1\n",
      "..  ...  ...  ...  ... ..\n",
      "70  6.5  3.0  5.8  2.2  3\n",
      "71  7.6  3.0  6.6  2.1  3\n",
      "72  4.9  2.5  4.5  1.7  3\n",
      "73  7.3  2.9  6.3  1.8  3\n",
      "74  6.7  2.5  5.8  1.8  3\n",
      "75  7.2  3.6  6.1  2.5  3\n",
      "76  6.5  3.2  5.1  2.0  3\n",
      "77  6.4  2.7  5.3  1.9  3\n",
      "78  6.8  3.0  5.5  2.1  3\n",
      "79  5.7  2.5  5.0  2.0  3\n",
      "80  5.8  2.8  5.1  2.4  3\n",
      "81  6.4  3.2  5.3  2.3  3\n",
      "82  6.5  3.0  5.5  1.8  3\n",
      "83  7.7  3.8  6.7  2.2  3\n",
      "84  7.7  2.6  6.9  2.3  3\n",
      "85  6.0  2.2  5.0  1.5  3\n",
      "86  6.9  3.2  5.7  2.3  3\n",
      "87  5.6  2.8  4.9  2.0  3\n",
      "88  7.7  2.8  6.7  2.0  3\n",
      "89  6.3  2.7  4.9  1.8  3\n",
      "90  6.7  3.3  5.7  2.1  3\n",
      "91  7.2  3.2  6.0  1.8  3\n",
      "92  6.2  2.8  4.8  1.8  3\n",
      "93  6.1  3.0  4.9  1.8  3\n",
      "94  6.4  2.8  5.6  2.1  3\n",
      "95  7.2  3.0  5.8  1.6  3\n",
      "96  7.4  2.8  6.1  1.9  3\n",
      "97  7.9  3.8  6.4  2.0  3\n",
      "98  6.4  2.8  5.6  2.2  3\n",
      "99  6.3  2.8  5.1  1.5  3\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DataFrame = pd.read_csv('./docs/iris.csv', header = None)\n",
    "print(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2  1. ]\n",
      " [ 4.9  3.   1.4  0.2  1. ]\n",
      " [ 4.7  3.2  1.3  0.2  1. ]\n",
      " [ 4.6  3.1  1.5  0.2  1. ]\n",
      " [ 5.   3.6  1.4  0.2  1. ]\n",
      " [ 5.4  3.9  1.7  0.4  1. ]\n",
      " [ 4.6  3.4  1.4  0.3  1. ]\n",
      " [ 5.   3.4  1.5  0.2  1. ]\n",
      " [ 4.4  2.9  1.4  0.2  1. ]\n",
      " [ 4.9  3.1  1.5  0.1  1. ]\n",
      " [ 5.4  3.7  1.5  0.2  1. ]\n",
      " [ 4.8  3.4  1.6  0.2  1. ]\n",
      " [ 4.8  3.   1.4  0.1  1. ]\n",
      " [ 4.3  3.   1.1  0.1  1. ]\n",
      " [ 5.8  4.   1.2  0.2  1. ]\n",
      " [ 5.7  4.4  1.5  0.4  1. ]\n",
      " [ 5.4  3.9  1.3  0.4  1. ]\n",
      " [ 5.1  3.5  1.4  0.3  1. ]\n",
      " [ 5.7  3.8  1.7  0.3  1. ]\n",
      " [ 5.1  3.8  1.5  0.3  1. ]\n",
      " [ 5.4  3.4  1.7  0.2  1. ]\n",
      " [ 5.1  3.7  1.5  0.4  1. ]\n",
      " [ 4.6  3.6  1.   0.2  1. ]\n",
      " [ 5.1  3.3  1.7  0.5  1. ]\n",
      " [ 4.8  3.4  1.9  0.2  1. ]\n",
      " [ 5.   3.   1.6  0.2  1. ]\n",
      " [ 5.   3.4  1.6  0.4  1. ]\n",
      " [ 5.2  3.5  1.5  0.2  1. ]\n",
      " [ 5.2  3.4  1.4  0.2  1. ]\n",
      " [ 4.7  3.2  1.6  0.2  1. ]\n",
      " [ 4.8  3.1  1.6  0.2  1. ]\n",
      " [ 5.4  3.4  1.5  0.4  1. ]\n",
      " [ 7.   3.2  4.7  1.4  2. ]\n",
      " [ 6.4  3.2  4.5  1.5  2. ]\n",
      " [ 6.9  3.1  4.9  1.5  2. ]\n",
      " [ 5.5  2.3  4.   1.3  2. ]\n",
      " [ 6.5  2.8  4.6  1.5  2. ]\n",
      " [ 5.7  2.8  4.5  1.3  2. ]\n",
      " [ 6.3  3.3  4.7  1.6  2. ]\n",
      " [ 4.9  2.4  3.3  1.   2. ]\n",
      " [ 6.6  2.9  4.6  1.3  2. ]\n",
      " [ 5.2  2.7  3.9  1.4  2. ]\n",
      " [ 5.   2.   3.5  1.   2. ]\n",
      " [ 5.9  3.   4.2  1.5  2. ]\n",
      " [ 6.   2.2  4.   1.   2. ]\n",
      " [ 6.1  2.9  4.7  1.4  2. ]\n",
      " [ 5.6  2.9  3.6  1.3  2. ]\n",
      " [ 6.7  3.1  4.4  1.4  2. ]\n",
      " [ 5.6  3.   4.5  1.5  2. ]\n",
      " [ 5.8  2.7  4.1  1.   2. ]\n",
      " [ 6.2  2.2  4.5  1.5  2. ]\n",
      " [ 5.6  2.5  3.9  1.1  2. ]\n",
      " [ 5.9  3.2  4.8  1.8  2. ]\n",
      " [ 6.1  2.8  4.   1.3  2. ]\n",
      " [ 6.3  2.5  4.9  1.5  2. ]\n",
      " [ 6.1  2.8  4.7  1.2  2. ]\n",
      " [ 6.4  2.9  4.3  1.3  2. ]\n",
      " [ 6.6  3.   4.4  1.4  2. ]\n",
      " [ 6.8  2.8  4.8  1.4  2. ]\n",
      " [ 6.7  3.   5.   1.7  2. ]\n",
      " [ 6.   2.9  4.5  1.5  2. ]\n",
      " [ 5.7  2.6  3.5  1.   2. ]\n",
      " [ 5.5  2.4  3.8  1.1  2. ]\n",
      " [ 5.5  2.4  3.7  1.   2. ]\n",
      " [ 5.8  2.7  3.9  1.2  2. ]\n",
      " [ 6.   2.7  5.1  1.6  2. ]\n",
      " [ 6.3  3.3  6.   2.5  3. ]\n",
      " [ 5.8  2.7  5.1  1.9  3. ]\n",
      " [ 7.1  3.   5.9  2.1  3. ]\n",
      " [ 6.3  2.9  5.6  1.8  3. ]\n",
      " [ 6.5  3.   5.8  2.2  3. ]\n",
      " [ 7.6  3.   6.6  2.1  3. ]\n",
      " [ 4.9  2.5  4.5  1.7  3. ]\n",
      " [ 7.3  2.9  6.3  1.8  3. ]\n",
      " [ 6.7  2.5  5.8  1.8  3. ]\n",
      " [ 7.2  3.6  6.1  2.5  3. ]\n",
      " [ 6.5  3.2  5.1  2.   3. ]\n",
      " [ 6.4  2.7  5.3  1.9  3. ]\n",
      " [ 6.8  3.   5.5  2.1  3. ]\n",
      " [ 5.7  2.5  5.   2.   3. ]\n",
      " [ 5.8  2.8  5.1  2.4  3. ]\n",
      " [ 6.4  3.2  5.3  2.3  3. ]\n",
      " [ 6.5  3.   5.5  1.8  3. ]\n",
      " [ 7.7  3.8  6.7  2.2  3. ]\n",
      " [ 7.7  2.6  6.9  2.3  3. ]\n",
      " [ 6.   2.2  5.   1.5  3. ]\n",
      " [ 6.9  3.2  5.7  2.3  3. ]\n",
      " [ 5.6  2.8  4.9  2.   3. ]\n",
      " [ 7.7  2.8  6.7  2.   3. ]\n",
      " [ 6.3  2.7  4.9  1.8  3. ]\n",
      " [ 6.7  3.3  5.7  2.1  3. ]\n",
      " [ 7.2  3.2  6.   1.8  3. ]\n",
      " [ 6.2  2.8  4.8  1.8  3. ]\n",
      " [ 6.1  3.   4.9  1.8  3. ]\n",
      " [ 6.4  2.8  5.6  2.1  3. ]\n",
      " [ 7.2  3.   5.8  1.6  3. ]\n",
      " [ 7.4  2.8  6.1  1.9  3. ]\n",
      " [ 7.9  3.8  6.4  2.   3. ]\n",
      " [ 6.4  2.8  5.6  2.2  3. ]\n",
      " [ 6.3  2.8  5.1  1.5  3. ]]\n"
     ]
    }
   ],
   "source": [
    "DataArray = DataFrame.values\n",
    "# or DataMatrix = DataFrame.as_matrix()\n",
    "print(DataArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n",
      "1 on the border and 0 inside in the array\n",
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#Write a Python program to create a 2d array with 1 on the border and 0 inside\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.ones((5,5))\n",
    "print(\"Original array:\")\n",
    "print(x)\n",
    "print(\"1 on the border and 0 inside in the array\")\n",
    "x[1:-1,1:-1] = 0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array:\n",
      "[[ 1.12  2.    3.45]\n",
      " [ 2.33  5.12  6.  ]]\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Write a Python program to test if specified values are present in an array.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1.12, 2.0, 3.45], [2.33, 5.12, 6.0]], float)\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(x)\n",
    "print(2 in x)\n",
    "print(0 in x)\n",
    "print(6 in x)\n",
    "print(2.3 in x)\n",
    "print(5.12 in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  5  6  9 10 12 15 18 20 21 24 25 27 30 33 35 36 39 40 42 45 48 50 51 54\n",
      " 55 57 60 63 65 66 69 70 72 75 78 80 81 84 85 87 90 93 95 96 99]\n",
      "2318\n"
     ]
    }
   ],
   "source": [
    "# Write a Python program (using numpy) to sum of all the multiples of 3 or 5 below 100.\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(1, 100)\n",
    "\n",
    "# find multiple of 3 or 5\n",
    "n= x[(x % 3 == 0) | (x % 5 == 0)]\n",
    "print(n[:1000])\n",
    "# print sum the numbers\n",
    "print(n.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient & Intercept 5.3935773612 -16.2811279931\n",
      "R-squared 0.524806275136\n",
      "p-value 0.275564857882\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sps\n",
    "\n",
    "x = [5.05, 6.75, 3.21, 2.66] \n",
    "y = [1.65, 26.5, -5.93, 7.96]\n",
    "(gradient,intercept,r_value,p_value,stderr) = sps.linregress(x,y) \n",
    "print (\"Gradient & Intercept\", gradient, intercept)\n",
    "print (\"R-squared\", r_value**2)\n",
    "print (\"p-value\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core NLP Tasks:\n",
    "**Today:**\n",
    "- Count words, counting frequency of words\n",
    "- Finding sentence boundaries\n",
    "- Part of speech tagging\n",
    "- Parsing the sentence structure\n",
    "\n",
    "**Latter:**\n",
    "- Identifying semantic role labeling\n",
    "- Named entity recognition\n",
    "- Co-reference and pronoun resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./data/test01.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "file = open('./data/test01.txt')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'test', 'for', 'text', 'in', 'python', 'list', 'and', 'the', 'words', 'are', 'randomly', 'created', 'by', 'me', 'haha,', 'the', 'words', 'are', 'good', 'or', 'not', 'good', 'really', 'depend', 'on', 'what', 'you', 'think', 'about', 'it.', 'are', 'you', 'kidding', 'me,', 'yes', 'i', 'am.', 'so', 'let', 'us', 'just', 'us', 'this', 'to', 'do', 'test.']\n"
     ]
    }
   ],
   "source": [
    "text2 = list()\n",
    "for line in file:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        text2.append(word)\n",
    "print(text2)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'am.',\n",
       " 'and',\n",
       " 'are',\n",
       " 'by',\n",
       " 'created',\n",
       " 'depend',\n",
       " 'do',\n",
       " 'for',\n",
       " 'good',\n",
       " 'haha,',\n",
       " 'i',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it.',\n",
       " 'just',\n",
       " 'kidding',\n",
       " 'let',\n",
       " 'list',\n",
       " 'me',\n",
       " 'me,',\n",
       " 'not',\n",
       " 'on',\n",
       " 'or',\n",
       " 'python',\n",
       " 'randomly',\n",
       " 'really',\n",
       " 'so',\n",
       " 'test',\n",
       " 'test.',\n",
       " 'text',\n",
       " 'the',\n",
       " 'think',\n",
       " 'this',\n",
       " 'to',\n",
       " 'us',\n",
       " 'what',\n",
       " 'words',\n",
       " 'yes',\n",
       " 'you'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just',\n",
       " 'do',\n",
       " 'python',\n",
       " 'randomly',\n",
       " 'yes',\n",
       " 'for',\n",
       " 'what',\n",
       " 'not',\n",
       " 'me',\n",
       " 'in',\n",
       " 'is',\n",
       " 'i',\n",
       " 'am.',\n",
       " 'haha,',\n",
       " 'or',\n",
       " 'let',\n",
       " 'created',\n",
       " 'about',\n",
       " 'good',\n",
       " 'you',\n",
       " 'really',\n",
       " 'words',\n",
       " 'to',\n",
       " 'us',\n",
       " 'test.',\n",
       " 'depend',\n",
       " 'kidding',\n",
       " 'by',\n",
       " 'think',\n",
       " 'this',\n",
       " 'the',\n",
       " 'it.',\n",
       " 'me,',\n",
       " 'a',\n",
       " 'text',\n",
       " 'list',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " 'are',\n",
       " 'test']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['just', 'do', 'python', 'randomly', 'yes']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(text2))[:5]  # the first 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['this', 'is', 'a', 'test', 'for', 'text', 'in', 'python', 'list', 'and', 'the', 'words', 'are', 'randomly', 'created', 'by', 'me', 'haha,', 'good', 'or', 'not', 'really', 'depend', 'on', 'what', 'you', 'think', 'about', 'it.', 'kidding', 'me,', 'yes', 'i', 'am.', 'so', 'let', 'us', 'just', 'to', 'do', 'test.'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "dist = nltk.FreqDist(text2)\n",
    "len(dist)\n",
    "dist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[u'this']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'words', 'good']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_define_choose_word = [w for w in dist.keys() if len(w) > 3 and dist[w] > 1]\n",
    "self_define_choose_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'lists', 'listing', 'listings']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "\n",
    "input_text = \"List listed lists listing listings\"\n",
    "word = input_text.lower().split(' ')\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'list', 'list', 'list', 'list']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'rights',\n",
       " 'of']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization : stemming, but resulting stems are all valid words\n",
    "\n",
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "udhr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers',\n",
       " 'declar',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'preambl',\n",
       " 'wherea',\n",
       " 'recognit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inher',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalien',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just stemming gives you non-valid words many sometimes\n",
    "[porter.stem(t) for t in udhr[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma = nltk.WordNetLemmatizer()\n",
    "[lemma.lemmatize(t) for t in udhr[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'drink',\n",
       " 'a',\n",
       " 'sugary',\n",
       " 'drink',\n",
       " 'before',\n",
       " 'bed',\n",
       " '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization: splitting a sentence into words/tokens\n",
    "\n",
    "text11 = \"Children shouldn't drink a sugary drink before bed.\"\n",
    "nltk.word_tokenize(text11)  # also have sent_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children', \"shouldn't\", 'drink', 'a', 'sugary', 'drink', 'before', 'bed.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different from just split\n",
    "text11.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![]('./pics/20180112_01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
