{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - MNIST Fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lots of Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build predictive models in Python we use a set of libraries that are imported here. In particular **pandas** and **sklearn** are particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "from TAS_Python_Utilities import data_viz\n",
    "from TAS_Python_Utilities import data_viz_target\n",
    "from TAS_Python_Utilities import visualize_tree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a dictionary to store simple model perofrmance comparions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_accuracy_comparisons = dict()\n",
    "model_valid_accuracy_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38730</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>154</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58804</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22012</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>194</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "3896       3       0       0       0       0       0       0       0       0   \n",
       "38730      4       0       0       0       0       0       0       0       0   \n",
       "4955       5       0       0       0       0       0       0       0       0   \n",
       "58804      9       0       0       0       0       0       0       0       0   \n",
       "22012      2       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "3896        0    ...            0         0         0         0         0   \n",
       "38730       0    ...           93        60         0         0       175   \n",
       "4955        0    ...            0         0         0         0         0   \n",
       "58804       0    ...            0         0         0         0         0   \n",
       "22012       0    ...            4         0         0       186       194   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "3896          0         0         0         0         0  \n",
       "38730       154        90         0         0         0  \n",
       "4955          0         0         0         0         0  \n",
       "58804         0         0         0         0         0  \n",
       "22012       139         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the distribution of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    633\n",
       "6    632\n",
       "7    614\n",
       "4    613\n",
       "0    599\n",
       "1    592\n",
       "8    591\n",
       "3    586\n",
       "9    576\n",
       "5    564\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无sample情况下每个都有6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.481667</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>0.156167</td>\n",
       "      <td>0.354333</td>\n",
       "      <td>0.651333</td>\n",
       "      <td>2.037667</td>\n",
       "      <td>5.624500</td>\n",
       "      <td>...</td>\n",
       "      <td>34.438833</td>\n",
       "      <td>22.808833</td>\n",
       "      <td>16.043833</td>\n",
       "      <td>18.516333</td>\n",
       "      <td>23.572167</td>\n",
       "      <td>18.445833</td>\n",
       "      <td>8.39100</td>\n",
       "      <td>2.446667</td>\n",
       "      <td>0.799833</td>\n",
       "      <td>0.09900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.861240</td>\n",
       "      <td>0.022357</td>\n",
       "      <td>0.067041</td>\n",
       "      <td>0.199979</td>\n",
       "      <td>1.033653</td>\n",
       "      <td>2.656179</td>\n",
       "      <td>5.452804</td>\n",
       "      <td>7.120315</td>\n",
       "      <td>13.486594</td>\n",
       "      <td>24.010878</td>\n",
       "      <td>...</td>\n",
       "      <td>57.494857</td>\n",
       "      <td>48.358305</td>\n",
       "      <td>41.134312</td>\n",
       "      <td>44.421676</td>\n",
       "      <td>52.694398</td>\n",
       "      <td>45.566455</td>\n",
       "      <td>28.87633</td>\n",
       "      <td>16.208165</td>\n",
       "      <td>9.114436</td>\n",
       "      <td>3.20212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>232.00000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      4.481667     0.000500     0.002500     0.018667     0.052333   \n",
       "std       2.861240     0.022357     0.067041     0.199979     1.033653   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000     1.000000     3.000000     5.000000    56.000000   \n",
       "\n",
       "            pixel5       pixel6       pixel7       pixel8       pixel9  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      0.156167     0.354333     0.651333     2.037667     5.624500   \n",
       "std       2.656179     5.452804     7.120315    13.486594    24.010878   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     116.000000   202.000000   198.000000   194.000000   232.000000   \n",
       "\n",
       "          ...         pixel775     pixel776     pixel777     pixel778  \\\n",
       "count     ...      6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      ...        34.438833    22.808833    16.043833    18.516333   \n",
       "std       ...        57.494857    48.358305    41.134312    44.421676   \n",
       "min       ...         0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...         0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...         0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...        57.000000     7.000000     0.000000     0.000000   \n",
       "max       ...       253.000000   255.000000   241.000000   249.000000   \n",
       "\n",
       "          pixel779     pixel780    pixel781     pixel782     pixel783  \\\n",
       "count  6000.000000  6000.000000  6000.00000  6000.000000  6000.000000   \n",
       "mean     23.572167    18.445833     8.39100     2.446667     0.799833   \n",
       "std      52.694398    45.566455    28.87633    16.208165     9.114436   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "max     255.000000   255.000000   232.00000   226.000000   203.000000   \n",
       "\n",
       "         pixel784  \n",
       "count  6000.00000  \n",
       "mean      0.09900  \n",
       "std       3.20212  \n",
       "min       0.00000  \n",
       "25%       0.00000  \n",
       "50%       0.00000  \n",
       "75%       0.00000  \n",
       "max     170.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())\n",
    "if(dataset.select_dtypes(include=[np.object]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.object]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise fields\n",
    "#data_viz(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualise fields in relation to target\n",
    "#data_viz_target(dataset, \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the descriptive features we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 798 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0kRfiApwg8kRfiBpAg/kBThB5L6P3CvcYP6tkfVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d30b4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2544 ]  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEbNJREFUeJzt3W2MVeW1B/D/chhgYMbh7TKMQBiMWIMvF5IJMalir9wS\nMCRIYgyYEK4xTGOa5pLU5Br7oX5pNDe2vXwwTaZXUjS9tibFiMaY6ISITZoKGC7agkpxKjPOMBRw\neJGxAqsfZmOmOHutw9n7nH0O6/9LCDNnnT3nYcOffWbWfp5HVBVEFM91RQ+AiIrB8BMFxfATBcXw\nEwXF8BMFxfATBcXwEwXF8BMFxfATBTWhmi8mIrydsAImTpyYWps2bZp57KlTp8z6pEmTzPpXX31l\n1qdPn55aGxwcNI+l8qiqlPK8TOEXkVUAtgJoAPC/qvp0lq9Xr667zn4DdenSJbM+YYL913DhwgWz\n3t7enlpbu3ateeyOHTvMekdHh1n3AvzAAw+k1p555hnzWO/PnfW8R1f2234RaQDwLIDVABYD2CAi\ni/MaGBFVVpbv+ZcBOKyqR1T17wB+A8C+zBBRzcgS/rkAjo75vC957J+ISJeI7BWRvRlei4hyVvEf\n+KlqN4BugD/wI6olWa78/QDmj/l8XvIYEdWBLOHfA2CRiCwUkYkA1gPYmc+wiKjSJMtKPiJyH4D/\nwWirb5uq/sR5ft2+7bfaSkW3lLq7u1NrK1euNI995513zHpPT49ZX7ZsmVlfuHBhas27x+Chhx4y\n65VUz23EqvT5VfV1AK9n+RpEVAze3ksUFMNPFBTDTxQUw08UFMNPFBTDTxRUVefz17Msfd3m5maz\nvnnzZrP+8MMPm3VrTv2ZM2fMY2fNmmXWvbHPnDnTrDc0NKTW5s+fn1oDgF27dpn1l156yay/8MIL\nqbWzZ8+ax9ZyHz8vvPITBcXwEwXF8BMFxfATBcXwEwXF8BMFlWlK71W/WB1P6V29enVqbd26deax\nixYtMuve6r2nT58269YKuo2Njeax7777rllfvNhek/WTTz4x60uXLk2tnThxwjzWahMC/rLk1nk/\ndOiQeezWrVvN+t69tbsqXalTennlJwqK4ScKiuEnCorhJwqK4ScKiuEnCorhJwqKff7EzTffbNY/\n/PDD1Nobb7xhHvvZZ5+Z9azbZFu8qatffvmlWfeWsB4eHi77+JaWFvPYyZMnm/Us05W9c3rHHXeY\n9VWrVpl1796MSi4Fzz4/EZkYfqKgGH6ioBh+oqAYfqKgGH6ioBh+oqAyLd0tIr0AzgC4COCCqnbm\nMagibNmyxax/9NFHqTVrPj3gz6n3lse2lub2eH1877W/+OILs97a2mrWrTn5TU1N5rHnz58361Om\nTDHr1j0OWc4pADz77LNmfePGjWa9FpYGz2Pd/n9T1b/l8HWIqIr4tp8oqKzhVwBvicg+EenKY0BE\nVB1Z3/bfpar9IjIbwJsickhVd499QvKfAv9jIKoxma78qtqf/D4E4GUAy8Z5TreqdtbzDwOJrkVl\nh19EpopIy+WPAawE8EFeAyOiysrytr8NwMsicvnr/J+q2nNbiahmlB1+VT0C4F9zHEuhFi5caNYP\nHjyYWpszZ4557NGjR8saU6msueMXL140j/Xm43tr54+MjJj15OIwLm8+/ty5c826t+6/NWd+wYIF\n5rF79uwx697fedZ7GKqBrT6ioBh+oqAYfqKgGH6ioBh+oqAYfqKg8pjVVxeWL19u1i9cuGDWh4aG\nUmveFtzetFfrawP+9E+vnWfxprZ6rUBvCWxr7N6fy5uOPDAwYNbXrFmTWvPOWV9fn1n3lvZesWKF\nWX/ttdfMejXwyk8UFMNPFBTDTxQUw08UFMNPFBTDTxQUw08UVJg+//r168261/e1pmB6PeGJEyea\nda/f7W2zbU2N9XrlnqxLXGfR399v1mfMmGHWb7jhhtRaT0+Peax338eBAwfM+u23327W2ecnosIw\n/ERBMfxEQTH8REEx/ERBMfxEQTH8REFdM31+b6vpW2+91axbS3N7zp07Z9ZnzZpl1r2lvb0+v9XL\nz7pEtLX8NZBtq2nv3grvvHnLilvbi3vrEHj/nry1BO6++26z3tHRkVrr7e01j80Lr/xEQTH8REEx\n/ERBMfxEQTH8REEx/ERBMfxEQbl9fhHZBmANgCFVvS15bAaA3wLoANAL4EFVPVW5YfoeffRRs37k\nyBGzbvWEAXt+t9cT9urenHlVNetZeu1eH7+xsTHT8dbYvD699+fyztu0adPKPtb799DS0mLWDx8+\nbNY3bNiQWnvqqafMY/NSypX/VwBWXfHY4wB6VHURgJ7kcyKqI274VXU3gJNXPLwWwPbk4+0A7s95\nXERUYeV+z9+mqpfvbxwE0JbTeIioSjLf26+qKiKp35SKSBeArqyvQ0T5KvfKf0xE2gEg+T11p0lV\n7VbVTlXtLPO1iKgCyg3/TgCbko83AXgln+EQUbW44ReRFwH8AcC3RKRPRB4B8DSA74rIxwD+Pfmc\niOqI+z2/qqY1JO0NyKusrc3+maPXa/d6zrt27Uqt3XvvveaxJ06cMOsnT17ZTMmPN2+9qanJrHvr\n13v98CyGh4fN+uzZs836p59+mlrz7iE4ffq0WV+yZIlZ99Z4mDNnjlmvBt7hRxQUw08UFMNPFBTD\nTxQUw08UFMNPFNQ1s3T3Y489ZtZvueUWs97VZd+BPG/evNTanXfeaR67f/9+sz516lSz7i1xbbXj\nvKmr3hbe1vbfADBhgv1PyGoleq/d2tpq1j3WdGPr7xPwz7m3Rferr75q1g8dOmTWq4FXfqKgGH6i\noBh+oqAYfqKgGH6ioBh+oqAYfqKgxFsWOtcXM5b7qnUzZ85MrS1fvtw8duPGjWZ9cHDQrHs9YWt6\nqtevnjx5slkfGRkx6x5rKrU3bba9vd2se1N6b7rpptRad3e3eezbb79t1o8fP27Wi6SqUsrzeOUn\nCorhJwqK4ScKiuEnCorhJwqK4ScKiuEnCop9/irwesbe3PB9+/aZdWsbbW8LbW9J87Nnz5p1bwls\na+lwbz6/t+y41+e/5557UmsrVtgrz3tLlnvnNYssW64D7PMTkYPhJwqK4ScKiuEnCorhJwqK4ScK\niuEnCspdt19EtgFYA2BIVW9LHnsSwGYAlyc1P6Gqr1dqkNXg9W2z9F69bay9tfWtPj6Qreec9Wt7\nvXrrPgJvrQHvHgPvPgDreG/d/t7eXrPuydqrr4ZS/tX8CsCqcR7/uaouSX7VdfCJInLDr6q7AZys\nwliIqIqyfM//AxE5ICLbRGR6biMioqooN/y/AHAjgCUABgD8NO2JItIlIntFZG+Zr0VEFVBW+FX1\nmKpeVNVLAH4JYJnx3G5V7VTVznIHSUT5Kyv8IjJ2WdV1AD7IZzhEVC2ltPpeBPAdALNEpA/AjwF8\nR0SWAFAAvQC+V8ExElEFuOFX1Q3jPPxcBcZyzfLmhmedO271u7P2mxsaGsy6d59Alq8tYk9Lb2lp\nMevWeTt37px5bAS8w48oKIafKCiGnygohp8oKIafKCiGnygot9UXRSWnYHqtOm9KrzdtNku7zXtt\nj9emtHjj9rYP96b0WrL+ua8FvPITBcXwEwXF8BMFxfATBcXwEwXF8BMFxfATBcU+fxVkXbq7qanJ\nrFtTW0dGRsxjvV67NzavF59lWXHvHgJvbNaUYW9Z8Ah45ScKiuEnCorhJwqK4ScKiuEnCorhJwqK\n4ScKin3+RCW36PZ67d58/Szz2r3Xzjqv3RubxTvn3v0NHuv4ethCu9J45ScKiuEnCorhJwqK4ScK\niuEnCorhJwqK4ScKyu3zi8h8AM8DaAOgALpVdauIzADwWwAdAHoBPKiqpyo31PrlbUU9YULlbrfw\n+vhZ1r4H/LUKmpubU2ve/Q1eL96rW1+fff7SrvwXAPxQVRcDuBPA90VkMYDHAfSo6iIAPcnnRFQn\n3PCr6oCqvpd8fAbAQQBzAawFsD152nYA91dqkESUv6v6nl9EOgAsBfBHAG2qOpCUBjH6bQER1YmS\nv9kUkWYAvwOwRVVPi8jXNVVVEdGU47oAdGUdKBHlq6Qrv4g0YjT4v1bVHcnDx0SkPam3Axga71hV\n7VbVTlXtzGPARJQPN/wyeol/DsBBVf3ZmNJOAJuSjzcBeCX/4RFRpZTytv/bADYCeF9E9iePPQHg\naQAvicgjAP4K4MHKDJG8qa9Zlsf2jvVagefPnzfr1rLiw8PD5rFeizTr1ufRueFX1d8DkJTyinyH\nQ0TVwjv8iIJi+ImCYviJgmL4iYJi+ImCYviJguLS3VVw8eJFs+5tRd3a2mrWremp586dM4+dPn26\nWfd65V6v3fqze1OZvT5/lmm53rLg3v0L1wJe+YmCYviJgmL4iYJi+ImCYviJgmL4iYJi+ImCYp+/\nDkyZMsWsDwwMpNa8XrrX5x8aGneBpq9df/31Zt26T8Dr449dKm483tLfFu+css9PRNcshp8oKIaf\nKCiGnygohp8oKIafKCiGnygo9vmrIOsW3f39/WZ9ZGQktTZnzhzzWG8tAW8L7qlTp5p1izVuwF/H\nwFtLoLGx8arHFAmv/ERBMfxEQTH8REEx/ERBMfxEQTH8REEx/ERBuX1+EZkP4HkAbQAUQLeqbhWR\nJwFsBnA8eeoTqvp6pQZaz7x+s7c2/ueff27WFyxYkFrzeuknT540697a+N6+AJMmTUqtZVnzv5Tj\ns3ztCEq5yecCgB+q6nsi0gJgn4i8mdR+rqrPVG54RFQpbvhVdQDAQPLxGRE5CGBupQdGRJV1Ve+b\nRKQDwFIAf0we+oGIHBCRbSIy7npQItIlIntFZG+mkRJRrkoOv4g0A/gdgC2qehrALwDcCGAJRt8Z\n/HS841S1W1U7VbUzh/ESUU5KCr+INGI0+L9W1R0AoKrHVPWiql4C8EsAyyo3TCLKmxt+GV1C9TkA\nB1X1Z2Mebx/ztHUAPsh/eERUKaX8tP/bADYCeF9E9iePPQFgg4gswWj7rxfA9yoywjrgtZyam5vN\n+uTJk836vHnzzLrVTvNaed5046xbWVtf33ttr0XqLTtunXfv78Rrr14LSvlp/+8BjLeAOnv6RHWM\nd/gRBcXwEwXF8BMFxfATBcXwEwXF8BMFxaW7c+BNex0cHDTrVp8e8LeT7uvrS61504W9Xru3tLfH\nWvrbG9vs2bPNujf23bt3p9ascxYFr/xEQTH8REEx/ERBMfxEQTH8REEx/ERBMfxEQYmqVu/FRI4D\n+OuYh2YB+FvVBnB1anVstTougGMrV55jW6Cq/1LKE6sa/m+8uMjeWl3br1bHVqvjAji2chU1Nr7t\nJwqK4ScKqujwdxf8+pZaHVutjgvg2MpVyNgK/Z6fiIpT9JWfiApSSPhFZJWIfCgih0Xk8SLGkEZE\nekXkfRHZX/QWY8k2aEMi8sGYx2aIyJsi8nHyu71+dXXH9qSI9Cfnbr+I3FfQ2OaLyC4R+bOI/ElE\n/jN5vNBzZ4yrkPNW9bf9ItIA4CMA3wXQB2APgA2q+ueqDiSFiPQC6FTVwnvCIrIcwFkAz6vqbclj\n/w3gpKo+nfzHOV1V/6tGxvYkgLNF79ycbCjTPnZnaQD3A/gPFHjujHE9iALOWxFX/mUADqvqEVX9\nO4DfAFhbwDhqnqruBnDlrhtrAWxPPt6O0X88VZcytpqgqgOq+l7y8RkAl3eWLvTcGeMqRBHhnwvg\n6JjP+1BbW34rgLdEZJ+IdBU9mHG0JdumA8AggLYiBzMOd+fmarpiZ+maOXfl7HidN/7A75vuUtUl\nAFYD+H7y9rYm6ej3bLXUrilp5+ZqGWdn6a8Vee7K3fE6b0WEvx/A/DGfz0seqwmq2p/8PgTgZdTe\n7sPHLm+Smvw+VPB4vlZLOzePt7M0auDc1dKO10WEfw+ARSKyUEQmAlgPYGcB4/gGEZma/CAGIjIV\nwErU3u7DOwFsSj7eBOCVAsfyT2pl5+a0naVR8LmruR2vVbXqvwDch9Gf+P8FwI+KGEPKuG4E8P/J\nrz8VPTYAL2L0beBXGP3ZyCMAZgLoAfAxgLcAzKihsb0A4H0ABzAatPaCxnYXRt/SHwCwP/l1X9Hn\nzhhXIeeNd/gRBcUf+BEFxfATBcXwEwXF8BMFxfATBcXwEwXF8BMFxfATBfUPY+0mik+zn1QAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d1f16d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1241 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d0e5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 143 ]  Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP1FQDD9RUP8PKTUw9O4rTukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134f8fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2131 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1116f1e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4625 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7851h+0p1LIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134c9a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4132 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI7Ec9YRScgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124bceac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 492 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124c36fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3307 ]  Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niZxi8RM5xeIncur/AUQIhLT+hXwTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134cce4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a sample of images from the dataset\n",
    "for i in range(0, 9):\n",
    "    i_rand = randint(0, X.shape[0])\n",
    "\n",
    "    print(\"[\", i_rand, \"] \", classes[Y[i_rand]])\n",
    "    two_d = (X.iloc[i_rand].values.reshape(28, 28))\n",
    "    pyplot.imshow(two_d, cmap='gray')\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data (important for some models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a **training set**, a **vaidation set**, and a **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Very Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the decision tree so we can see what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(my_tree, feature_names, fileName='dt_over.png')\n",
    "#Image(filename='dt_over.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       277\n",
      "          1       1.00      1.00      1.00       310\n",
      "          2       1.00      1.00      1.00       323\n",
      "          3       1.00      1.00      1.00       293\n",
      "          4       1.00      1.00      1.00       323\n",
      "          5       1.00      1.00      1.00       252\n",
      "          6       1.00      1.00      1.00       332\n",
      "          7       1.00      1.00      1.00       303\n",
      "          8       1.00      1.00      1.00       299\n",
      "          9       1.00      1.00      1.00       288\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>277</td>\n",
       "      <td>310</td>\n",
       "      <td>323</td>\n",
       "      <td>293</td>\n",
       "      <td>323</td>\n",
       "      <td>252</td>\n",
       "      <td>332</td>\n",
       "      <td>303</td>\n",
       "      <td>299</td>\n",
       "      <td>288</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          277    0    0    0    0    0    0    0    0    0   277\n",
       "1            0  310    0    0    0    0    0    0    0    0   310\n",
       "2            0    0  323    0    0    0    0    0    0    0   323\n",
       "3            0    0    0  293    0    0    0    0    0    0   293\n",
       "4            0    0    0    0  323    0    0    0    0    0   323\n",
       "5            0    0    0    0    0  252    0    0    0    0   252\n",
       "6            0    0    0    0    0    0  332    0    0    0   332\n",
       "7            0    0    0    0    0    0    0  303    0    0   303\n",
       "8            0    0    0    0    0    0    0    0  299    0   299\n",
       "9            0    0    0    0    0    0    0    0    0  288   288\n",
       "All        277  310  323  293  323  252  332  303  299  288  3000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.701666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.64      0.68       141\n",
      "          1       0.89      0.89      0.89       111\n",
      "          2       0.65      0.65      0.65       141\n",
      "          3       0.74      0.76      0.75       106\n",
      "          4       0.54      0.53      0.54       116\n",
      "          5       0.76      0.79      0.78       117\n",
      "          6       0.39      0.48      0.43       128\n",
      "          7       0.79      0.75      0.77       113\n",
      "          8       0.86      0.77      0.82       124\n",
      "          9       0.79      0.82      0.80       103\n",
      "\n",
      "avg / total       0.71      0.70      0.70      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>123</td>\n",
       "      <td>111</td>\n",
       "      <td>139</td>\n",
       "      <td>109</td>\n",
       "      <td>112</td>\n",
       "      <td>122</td>\n",
       "      <td>158</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>107</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           90    2    3    8    2    4   32    0    0    0   141\n",
       "1            0   99    1    6    1    0    1    0    1    2   111\n",
       "2            4    0   91    2   18    0   24    0    2    0   141\n",
       "3            4    5    4   81    5    1    4    0    1    1   106\n",
       "4            0    3   22    5   61    0   23    0    1    1   116\n",
       "5            1    0    0    0    2   93    2    9    4    6   117\n",
       "6           23    1   16    5   17    0   62    0    4    0   128\n",
       "7            0    0    0    0    0   16    0   85    0   12   113\n",
       "8            1    1    2    1    6    1   10    5   96    1   124\n",
       "9            0    0    0    1    0    7    0    9    2   84   103\n",
       "All        123  111  139  109  112  122  158  108  111  107  1200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.739444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.66      0.67       181\n",
      "          1       0.92      0.91      0.91       171\n",
      "          2       0.58      0.56      0.57       169\n",
      "          3       0.76      0.76      0.76       187\n",
      "          4       0.59      0.59      0.59       174\n",
      "          5       0.85      0.87      0.86       195\n",
      "          6       0.44      0.47      0.45       172\n",
      "          7       0.83      0.84      0.84       198\n",
      "          8       0.84      0.83      0.83       168\n",
      "          9       0.88      0.88      0.88       185\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>174</td>\n",
       "      <td>168</td>\n",
       "      <td>163</td>\n",
       "      <td>188</td>\n",
       "      <td>172</td>\n",
       "      <td>198</td>\n",
       "      <td>186</td>\n",
       "      <td>201</td>\n",
       "      <td>165</td>\n",
       "      <td>185</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          119    4   11   13    2    1   27    0    4    0   181\n",
       "1            2  155    2    7    2    0    3    0    0    0   171\n",
       "2            4    0   94    4   32    0   33    0    2    0   169\n",
       "3            9    8    1  143   10    1   13    0    2    0   187\n",
       "4            2    1   34    8  102    0   20    0    7    0   174\n",
       "5            0    0    0    0    0  169    1   17    0    8   195\n",
       "6           35    0   18   10   21    1   81    0    6    0   172\n",
       "7            0    0    0    0    0   19    0  167    0   12   198\n",
       "8            3    0    3    2    3    1    8    6  139    3   168\n",
       "9            0    0    0    1    0    6    0   11    5  162   185\n",
       "All        174  168  163  188  172  198  186  201  165  185  1800"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less Overiftted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree, setting min samples per leaf to a sensible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the decision tree so we can see what it is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualise the decision tree\n",
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(my_tree, feature_names, fileName=\"dt_under.png\")\n",
    "#Image(filename='dt_under.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.749\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.72      0.77       277\n",
      "          1       0.96      0.91      0.94       310\n",
      "          2       0.59      0.72      0.65       323\n",
      "          3       0.70      0.82      0.75       293\n",
      "          4       0.72      0.46      0.56       323\n",
      "          5       0.83      0.85      0.84       252\n",
      "          6       0.50      0.52      0.51       332\n",
      "          7       0.91      0.81      0.86       303\n",
      "          8       0.77      0.84      0.80       299\n",
      "          9       0.80      0.90      0.85       288\n",
      "\n",
      "avg / total       0.76      0.75      0.75      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>30</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>252</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>260</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>241</td>\n",
       "      <td>293</td>\n",
       "      <td>397</td>\n",
       "      <td>345</td>\n",
       "      <td>205</td>\n",
       "      <td>258</td>\n",
       "      <td>342</td>\n",
       "      <td>268</td>\n",
       "      <td>328</td>\n",
       "      <td>323</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          199    2    4   18    1    0   40    0   13    0   277\n",
       "1            0  282    4   18    0    2    3    0    1    0   310\n",
       "2            3    0  234    3   37    1   37    0    8    0   323\n",
       "3            1    8   10  240    1    8   23    0    2    0   293\n",
       "4            0    0   84   30  148    0   46    0   15    0   323\n",
       "5            0    0    0    0    0  215   10    5    5   17   252\n",
       "6           35    0   58   28   18    0  172    0   21    0   332\n",
       "7            0    0    0    0    0   14    0  245    1   43   303\n",
       "8            3    1    3    8    0   16    9    4  252    3   299\n",
       "9            0    0    0    0    0    2    2   14   10  260   288\n",
       "All        241  293  397  345  205  258  342  268  328  323  3000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.671666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.64      0.71       141\n",
      "          1       0.90      0.82      0.86       111\n",
      "          2       0.64      0.68      0.66       141\n",
      "          3       0.54      0.71      0.61       106\n",
      "          4       0.51      0.35      0.42       116\n",
      "          5       0.72      0.75      0.74       117\n",
      "          6       0.44      0.51      0.47       128\n",
      "          7       0.77      0.62      0.69       113\n",
      "          8       0.76      0.83      0.79       124\n",
      "          9       0.71      0.84      0.77       103\n",
      "\n",
      "avg / total       0.68      0.67      0.67      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>112</td>\n",
       "      <td>101</td>\n",
       "      <td>150</td>\n",
       "      <td>138</td>\n",
       "      <td>80</td>\n",
       "      <td>122</td>\n",
       "      <td>147</td>\n",
       "      <td>91</td>\n",
       "      <td>136</td>\n",
       "      <td>123</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3   4    5    6   7    8    9   All\n",
       "True                                                           \n",
       "0           90    0    4   19   0    1   23   0    4    0   141\n",
       "1            0   91    2    8   2    0    4   0    4    0   111\n",
       "2            2    0   96    0  19    0   21   0    3    0   141\n",
       "3            0    9    9   75   3    2    7   0    1    0   106\n",
       "4            1    0   24   18  41    0   24   0    8    0   116\n",
       "5            0    0    0    0   1   88    0  10    8   10   117\n",
       "6           19    0   14   15  12    0   65   0    3    0   128\n",
       "7            0    0    0    0   0   18    0  70    0   25   113\n",
       "8            0    1    1    3   2    7    3   3  103    1   124\n",
       "9            0    0    0    0   0    6    0   8    2   87   103\n",
       "All        112  101  150  138  80  122  147  91  136  123  1200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.695555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.61      0.69       181\n",
      "          1       0.95      0.87      0.91       171\n",
      "          2       0.52      0.59      0.55       169\n",
      "          3       0.67      0.79      0.72       187\n",
      "          4       0.59      0.39      0.47       174\n",
      "          5       0.77      0.87      0.82       195\n",
      "          6       0.39      0.44      0.42       172\n",
      "          7       0.84      0.73      0.78       198\n",
      "          8       0.68      0.80      0.73       168\n",
      "          9       0.80      0.83      0.81       185\n",
      "\n",
      "avg / total       0.70      0.70      0.69      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>153</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>140</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>222</td>\n",
       "      <td>114</td>\n",
       "      <td>220</td>\n",
       "      <td>194</td>\n",
       "      <td>173</td>\n",
       "      <td>198</td>\n",
       "      <td>192</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          111    1    4   15    1    0   37    0   12    0   181\n",
       "1            0  148    2   18    1    0    2    0    0    0   171\n",
       "2            1    0  100    0   29    0   29    0   10    0   169\n",
       "3            2    5    8  148    1    4   18    0    1    0   187\n",
       "4            0    0   44   23   67    0   23    0   17    0   174\n",
       "5            0    0    0    0    0  170    1    8    4   12   195\n",
       "6           25    1   33   15   14    0   76    0    8    0   172\n",
       "7            0    0    0    0    0   27    0  145    1   25   198\n",
       "8            1    0    1    3    1   15    7    4  134    2   168\n",
       "9            0    0    0    0    0    4    1   16   11  153   185\n",
       "All        140  155  192  222  114  220  194  173  198  192  1800"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Parameters Using a Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a cross validation to perfrom an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71226415  0.68483412  0.7535545   0.73634204  0.74761905  0.70714286\n",
      "  0.76372315  0.72792363  0.78229665  0.71807229]\n"
     ]
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "scores = cross_val_score(my_tree, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to using post pruning explicitly is to use a grid search through a large set of possible parameters. Here we try depths between 3 and 20 and different limits on the minimum number of samples per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.68142857142857138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.20968592,  0.31808448,  0.32249248,  0.32105637,  0.33199704,\n",
       "         0.33212149,  0.34387219,  0.35148787,  0.33465493,  0.32421494,\n",
       "         0.35487437,  0.32166505,  0.34316885,  0.33243656,  0.34130645,\n",
       "         0.34283841,  0.32045901,  0.51895392,  0.58753002,  0.57786   ,\n",
       "         0.54409587,  0.53961909,  0.53905809,  0.56862342,  0.54646146,\n",
       "         0.52564037,  0.53155398,  0.53497696,  0.56386638,  0.57064545,\n",
       "         0.53084052,  0.52977896]),\n",
       " 'mean_score_time': array([ 0.00249815,  0.00293946,  0.00255394,  0.00234902,  0.00270915,\n",
       "         0.00267851,  0.00341845,  0.00253522,  0.00239706,  0.00237751,\n",
       "         0.00318062,  0.00295532,  0.00312257,  0.00255692,  0.00249898,\n",
       "         0.00360692,  0.00236917,  0.00228143,  0.00294745,  0.00256765,\n",
       "         0.0034796 ,  0.00255048,  0.00275445,  0.00296557,  0.00251734,\n",
       "         0.00283718,  0.00288796,  0.00294101,  0.00285363,  0.00238156,\n",
       "         0.00241864,  0.00272608]),\n",
       " 'mean_test_score': array([ 0.48833333,  0.67380952,  0.68119048,  0.68095238,  0.68071429,\n",
       "         0.68071429,  0.68119048,  0.68047619,  0.68142857,  0.68095238,\n",
       "         0.68095238,  0.68119048,  0.68071429,  0.68119048,  0.68119048,\n",
       "         0.68047619,  0.51357143,  0.66380952,  0.66380952,  0.66380952,\n",
       "         0.66380952,  0.66380952,  0.66380952,  0.66380952,  0.66380952,\n",
       "         0.66380952,  0.66380952,  0.66380952,  0.66380952,  0.66380952,\n",
       "         0.66380952,  0.66380952]),\n",
       " 'mean_train_score': array([ 0.50236701,  0.71595214,  0.73046272,  0.73046272,  0.73046272,\n",
       "         0.73046272,  0.73046272,  0.73046272,  0.73046272,  0.73046272,\n",
       "         0.73046272,  0.73046272,  0.73046272,  0.73046272,  0.73046272,\n",
       "         0.73046272,  0.52858611,  0.71143479,  0.71143479,  0.71143479,\n",
       "         0.71143479,  0.71143479,  0.71143479,  0.71143479,  0.71143479,\n",
       "         0.71143479,  0.71143479,  0.71143479,  0.71143479,  0.71143479,\n",
       "         0.71143479,  0.71143479]),\n",
       " 'param_criterion': masked_array(data = ['gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
       "  'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'entropy' 'entropy' 'entropy'\n",
       "  'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
       "  'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_max_depth': masked_array(data = [3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 3 6 9 12 15 18 21 24 27 30 33\n",
       "  36 39 42 45 48],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_samples_split': masked_array(data = [200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200\n",
       "  200 200 200 200 200 200 200 200 200 200 200 200 200 200],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}),\n",
       " 'rank_test_score': array([32, 15,  2,  7, 10, 10,  2, 13,  1,  7,  7,  2, 10,  2,  2, 13, 31,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16], dtype=int32),\n",
       " 'split0_test_score': array([ 0.47741322,  0.65858298,  0.6638136 ,  0.66333809,  0.66286258,\n",
       "         0.66286258,  0.6638136 ,  0.66238707,  0.66428911,  0.66333809,\n",
       "         0.66333809,  0.6638136 ,  0.66286258,  0.6638136 ,  0.6638136 ,\n",
       "         0.66238707,  0.51355207,  0.66191155,  0.66191155,  0.66191155,\n",
       "         0.66191155,  0.66191155,  0.66191155,  0.66191155,  0.66191155,\n",
       "         0.66191155,  0.66191155,  0.66191155,  0.66191155,  0.66191155,\n",
       "         0.66191155,  0.66191155]),\n",
       " 'split0_train_score': array([ 0.49260849,  0.71578445,  0.72103004,  0.72103004,  0.72103004,\n",
       "         0.72103004,  0.72103004,  0.72103004,  0.72103004,  0.72103004,\n",
       "         0.72103004,  0.72103004,  0.72103004,  0.72103004,  0.72103004,\n",
       "         0.72103004,  0.53886505,  0.71578445,  0.71578445,  0.71578445,\n",
       "         0.71578445,  0.71578445,  0.71578445,  0.71578445,  0.71578445,\n",
       "         0.71578445,  0.71578445,  0.71578445,  0.71578445,  0.71578445,\n",
       "         0.71578445,  0.71578445]),\n",
       " 'split1_test_score': array([ 0.49928469,  0.68907964,  0.69861707,  0.69861707,  0.69861707,\n",
       "         0.69861707,  0.69861707,  0.69861707,  0.69861707,  0.69861707,\n",
       "         0.69861707,  0.69861707,  0.69861707,  0.69861707,  0.69861707,\n",
       "         0.69861707,  0.51359084,  0.66571292,  0.66571292,  0.66571292,\n",
       "         0.66571292,  0.66571292,  0.66571292,  0.66571292,  0.66571292,\n",
       "         0.66571292,  0.66571292,  0.66571292,  0.66571292,  0.66571292,\n",
       "         0.66571292,  0.66571292]),\n",
       " 'split1_train_score': array([ 0.51212553,  0.71611983,  0.73989539,  0.73989539,  0.73989539,\n",
       "         0.73989539,  0.73989539,  0.73989539,  0.73989539,  0.73989539,\n",
       "         0.73989539,  0.73989539,  0.73989539,  0.73989539,  0.73989539,\n",
       "         0.73989539,  0.51830718,  0.70708512,  0.70708512,  0.70708512,\n",
       "         0.70708512,  0.70708512,  0.70708512,  0.70708512,  0.70708512,\n",
       "         0.70708512,  0.70708512,  0.70708512,  0.70708512,  0.70708512,\n",
       "         0.70708512,  0.70708512]),\n",
       " 'std_fit_time': array([ 0.00104296,  0.00339556,  0.01605737,  0.0155046 ,  0.01314986,\n",
       "         0.01578343,  0.0229491 ,  0.00632501,  0.01606905,  0.01512289,\n",
       "         0.01688957,  0.01927805,  0.02746785,  0.00659132,  0.01687264,\n",
       "         0.02168143,  0.00753605,  0.02057707,  0.02017486,  0.0144428 ,\n",
       "         0.02930987,  0.01443303,  0.015921  ,  0.00045836,  0.01460564,\n",
       "         0.00858247,  0.01960707,  0.01108313,  0.01336741,  0.02078068,\n",
       "         0.01009166,  0.00739598]),\n",
       " 'std_score_time': array([  6.60419464e-05,   2.76565552e-04,   1.49965286e-04,\n",
       "          2.99215317e-05,   2.63214111e-04,   6.73532486e-05,\n",
       "          9.49382782e-04,   1.50084496e-04,   6.69956207e-05,\n",
       "          1.57356262e-05,   4.64320183e-04,   4.19497490e-04,\n",
       "          7.85589218e-04,   2.02059746e-04,   1.26719475e-04,\n",
       "          6.45995140e-04,   2.50339508e-05,   4.45842743e-05,\n",
       "          5.33699989e-04,   3.06367874e-05,   6.66499138e-04,\n",
       "          2.21610069e-04,   2.13623047e-04,   2.65836716e-05,\n",
       "          3.75509262e-05,   1.06096268e-04,   1.23023987e-04,\n",
       "          2.76207924e-04,   2.92539597e-04,   1.46389008e-04,\n",
       "          1.87516212e-04,   1.82151794e-04]),\n",
       " 'std_test_score': array([  1.09357254e-02,   1.52483149e-02,   1.74017184e-02,\n",
       "          1.76394738e-02,   1.78772291e-02,   1.78772291e-02,\n",
       "          1.74017184e-02,   1.81149845e-02,   1.71639631e-02,\n",
       "          1.76394738e-02,   1.76394738e-02,   1.74017184e-02,\n",
       "          1.78772291e-02,   1.74017184e-02,   1.74017184e-02,\n",
       "          1.81149845e-02,   1.93877749e-05,   1.90068221e-03,\n",
       "          1.90068221e-03,   1.90068221e-03,   1.90068221e-03,\n",
       "          1.90068221e-03,   1.90068221e-03,   1.90068221e-03,\n",
       "          1.90068221e-03,   1.90068221e-03,   1.90068221e-03,\n",
       "          1.90068221e-03,   1.90068221e-03,   1.90068221e-03,\n",
       "          1.90068221e-03,   1.90068221e-03]),\n",
       " 'std_train_score': array([ 0.00975852,  0.00016769,  0.00943267,  0.00943267,  0.00943267,\n",
       "         0.00943267,  0.00943267,  0.00943267,  0.00943267,  0.00943267,\n",
       "         0.00943267,  0.00943267,  0.00943267,  0.00943267,  0.00943267,\n",
       "         0.00943267,  0.01027893,  0.00434967,  0.00434967,  0.00434967,\n",
       "         0.00434967,  0.00434967,  0.00434967,  0.00434967,  0.00434967,\n",
       "         0.00434967,  0.00434967,  0.00434967,  0.00434967,  0.00434967,\n",
       "         0.00434967,  0.00434967])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.59      0.68       181\n",
      "          1       0.83      0.88      0.85       171\n",
      "          2       0.58      0.49      0.53       169\n",
      "          3       0.77      0.66      0.71       187\n",
      "          4       0.51      0.52      0.52       174\n",
      "          5       0.70      0.87      0.77       195\n",
      "          6       0.35      0.52      0.42       172\n",
      "          7       0.81      0.78      0.79       198\n",
      "          8       0.85      0.72      0.78       168\n",
      "          9       0.89      0.82      0.85       185\n",
      "\n",
      "avg / total       0.71      0.69      0.70      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>129</td>\n",
       "      <td>183</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>177</td>\n",
       "      <td>244</td>\n",
       "      <td>260</td>\n",
       "      <td>192</td>\n",
       "      <td>142</td>\n",
       "      <td>171</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          106    3   12    7    1    8   41    0    3    0   181\n",
       "1            0  151    1   10    2    0    5    0    2    0   171\n",
       "2            5    1   83    0   49    1   30    0    0    0   169\n",
       "3            5   10    3  123    7    4   35    0    0    0   187\n",
       "4            0    9   12   10   91    1   46    0    5    0   174\n",
       "5            0    0    0    0    0  170    1   21    2    1   195\n",
       "6           12    6   26    9   23    4   90    0    2    0   172\n",
       "7            0    0    0    0    0   24    0  155    1   18   198\n",
       "8            1    3    5    1    3   24    9    1  121    0   168\n",
       "9            0    0    0    0    1    8    3   15    6  152   185\n",
       "All        129  183  142  160  177  244  260  192  142  171  1800"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_tree = tree.DecisionTreeClassifier(min_samples_split=200, criterion='gini', max_depth=8)\n",
    "best_tree = best_tree.fit(X_train, y_train)\n",
    "\n",
    "# visualise the decision tree\n",
    "#feature_names = list(X_train.columns)\n",
    "#visualize_tree(best_tree, feature_names, 'dt_tuned.png')\n",
    "#Image(filename='dt_tuned.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use the same patterns to train other types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.RandomForestClassifier(n_estimators=300, \\\n",
    "                                           max_features = 3,\\\n",
    "                                           min_samples_split=200)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.73      0.73       141\n",
      "          1       0.92      0.86      0.89       111\n",
      "          2       0.69      0.74      0.72       141\n",
      "          3       0.60      0.85      0.70       106\n",
      "          4       0.56      0.60      0.58       116\n",
      "          5       0.93      0.59      0.72       117\n",
      "          6       0.50      0.26      0.34       128\n",
      "          7       0.70      0.84      0.76       113\n",
      "          8       0.90      0.94      0.92       124\n",
      "          9       0.73      0.88      0.80       103\n",
      "\n",
      "avg / total       0.73      0.72      0.71      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>140</td>\n",
       "      <td>104</td>\n",
       "      <td>152</td>\n",
       "      <td>151</td>\n",
       "      <td>124</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>136</td>\n",
       "      <td>129</td>\n",
       "      <td>124</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4   5   6    7    8    9   All\n",
       "True                                                           \n",
       "0          103    1    2   22    0   0   8    0    5    0   141\n",
       "1            1   96    8    5    1   0   0    0    0    0   111\n",
       "2            0    0  105    0   22   0  12    0    2    0   141\n",
       "3            2    6    2   90    2   0   3    0    1    0   106\n",
       "4            0    1   18   17   70   0  10    0    0    0   116\n",
       "5            0    0    0    0    0  69   0   30    2   16   117\n",
       "6           34    0   16   12   29   1  33    0    3    0   128\n",
       "7            0    0    0    0    0   1   0   95    0   17   113\n",
       "8            0    0    1    4    0   2   0    1  116    0   124\n",
       "9            0    0    0    1    0   1   0   10    0   91   103\n",
       "All        140  104  152  151  124  74  66  136  129  124  1200"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.1s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.3s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   0.8s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   0.8s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   0.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.1s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   1.3s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   1.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   1.4s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   0.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   1.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   1.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   1.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   1.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   1.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 8, 'min_samples_split': 200, 'n_estimators': 450}\n",
      "0.74619047619\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [200] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Random Forest\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.802222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.77      0.75       181\n",
      "          1       0.99      0.92      0.95       171\n",
      "          2       0.68      0.71      0.70       169\n",
      "          3       0.68      0.88      0.77       187\n",
      "          4       0.63      0.66      0.65       174\n",
      "          5       0.96      0.90      0.93       195\n",
      "          6       0.65      0.34      0.45       172\n",
      "          7       0.90      0.89      0.90       198\n",
      "          8       0.89      0.94      0.92       168\n",
      "          9       0.89      0.96      0.92       185\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>191</td>\n",
       "      <td>160</td>\n",
       "      <td>176</td>\n",
       "      <td>244</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>91</td>\n",
       "      <td>196</td>\n",
       "      <td>177</td>\n",
       "      <td>201</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          139    2    6   24    1    0   5    0    4    0   181\n",
       "1            0  158    3   10    0    0   0    0    0    0   171\n",
       "2            1    0  120    0   34    0  11    0    3    0   169\n",
       "3           10    0    1  165    5    0   6    0    0    0   187\n",
       "4            0    0   22   25  115    0   9    0    3    0   174\n",
       "5            0    0    0    0    0  175   0   12    1    7   195\n",
       "6           40    0   24   16   25    0  59    0    8    0   172\n",
       "7            0    0    0    0    0    5   0  177    0   16   198\n",
       "8            1    0    0    4    2    2   1    0  158    0   168\n",
       "9            0    0    0    0    0    0   0    7    0  178   185\n",
       "All        191  160  176  244  182  182  91  196  177  201  1800"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 50), \\\n",
    "                                      n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.724166666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.72      0.75       141\n",
      "          1       0.94      0.82      0.88       111\n",
      "          2       0.67      0.70      0.68       141\n",
      "          3       0.58      0.85      0.69       106\n",
      "          4       0.56      0.66      0.61       116\n",
      "          5       0.79      0.72      0.75       117\n",
      "          6       0.62      0.38      0.47       128\n",
      "          7       0.77      0.72      0.74       113\n",
      "          8       0.87      0.88      0.88       124\n",
      "          9       0.74      0.88      0.81       103\n",
      "\n",
      "avg / total       0.73      0.72      0.72      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>128</td>\n",
       "      <td>97</td>\n",
       "      <td>147</td>\n",
       "      <td>156</td>\n",
       "      <td>135</td>\n",
       "      <td>107</td>\n",
       "      <td>77</td>\n",
       "      <td>105</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1    2    3    4    5   6    7    8    9   All\n",
       "True                                                           \n",
       "0          101   1    7   20    1    1   4    0    6    0   141\n",
       "1            0  91    7   10    0    0   2    0    1    0   111\n",
       "2            0   0   98    1   34    0   6    0    2    0   141\n",
       "3            0   2    6   90    5    1   2    0    0    0   106\n",
       "4            0   1    8   16   76    0  13    0    2    0   116\n",
       "5            0   0    0    0    0   84   0   16    3   14   117\n",
       "6           26   1   19   14   18    0  48    0    2    0   128\n",
       "7            0   0    0    0    0   14   0   81    0   18   113\n",
       "8            0   1    2    4    1    3   2    2  109    0   124\n",
       "9            1   0    0    1    0    4   0    6    0   91   103\n",
       "All        128  97  147  156  135  107  77  105  125  123  1200"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=   7.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=   7.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  15.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  15.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  22.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  22.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total=  29.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total=  30.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total=  38.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total=  37.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total=  45.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total=  47.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total=  53.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total=  52.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 1.0min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total=  59.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 1.2min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 1.2min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 14.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), 'n_estimators': 300}\n",
      "0.55119047619\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.692222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.70      0.72       181\n",
      "          1       0.95      0.87      0.91       171\n",
      "          2       0.55      0.59      0.57       169\n",
      "          3       0.66      0.84      0.74       187\n",
      "          4       0.50      0.71      0.59       174\n",
      "          5       0.76      0.57      0.65       195\n",
      "          6       0.55      0.06      0.11       172\n",
      "          7       0.80      0.76      0.78       198\n",
      "          8       0.70      0.87      0.78       168\n",
      "          9       0.70      0.91      0.80       185\n",
      "\n",
      "avg / total       0.69      0.69      0.67      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>158</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>173</td>\n",
       "      <td>156</td>\n",
       "      <td>181</td>\n",
       "      <td>238</td>\n",
       "      <td>248</td>\n",
       "      <td>148</td>\n",
       "      <td>20</td>\n",
       "      <td>188</td>\n",
       "      <td>208</td>\n",
       "      <td>240</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          127    5   18   19    1    0   0    0   11    0   181\n",
       "1            0  148    3   19    1    0   0    0    0    0   171\n",
       "2            0    0  100    0   59    1   3    0    6    0   169\n",
       "3            6    1    9  158    9    0   0    0    0    4   187\n",
       "4            0    1   12   22  124    0   5    0   10    0   174\n",
       "5            1    0    0    0    0  112   0   35    8   39   195\n",
       "6           38    0   35   16   54    1  11    0   17    0   172\n",
       "7            0    0    0    0    0   25   0  151    4   18   198\n",
       "8            0    1    4    4    0    2   1    0  146   10   168\n",
       "9            1    0    0    0    0    7   0    2    6  169   185\n",
       "All        173  156  181  238  248  148  20  188  208  240  1800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 200), \\\n",
    "                                       n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.613333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.59      0.61       141\n",
      "          1       0.96      0.77      0.85       111\n",
      "          2       0.67      0.55      0.60       141\n",
      "          3       0.65      0.71      0.68       106\n",
      "          4       0.45      0.60      0.52       116\n",
      "          5       0.48      0.82      0.61       117\n",
      "          6       0.27      0.23      0.25       128\n",
      "          7       0.78      0.38      0.51       113\n",
      "          8       0.77      0.98      0.86       124\n",
      "          9       0.79      0.54      0.64       103\n",
      "\n",
      "avg / total       0.64      0.61      0.61      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>132</td>\n",
       "      <td>89</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>155</td>\n",
       "      <td>200</td>\n",
       "      <td>108</td>\n",
       "      <td>55</td>\n",
       "      <td>157</td>\n",
       "      <td>71</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1    2    3    4    5    6   7    8   9   All\n",
       "True                                                          \n",
       "0           83   1    5   13    2    0   26   0   11   0   141\n",
       "1            5  85    4   13    1    0    3   0    0   0   111\n",
       "2            1   0   78    1   33    0   25   0    3   0   141\n",
       "3           13   1    2   75    3    0   11   0    1   0   106\n",
       "4            3   0   16    7   70    0   12   0    8   0   116\n",
       "5            0   0    0    0    0   96    0   6    7   8   117\n",
       "6           27   2   12    6   46    0   29   0    6   0   128\n",
       "7            0   0    0    0    0   63    0  43    0   7   113\n",
       "8            0   0    0    1    0    0    2   0  121   0   124\n",
       "9            0   0    0    0    0   41    0   6    0  56   103\n",
       "All        132  89  117  116  155  200  108  55  157  71  1200"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=  13.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=50, total=  13.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  26.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=100, total=  27.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  42.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=150, total=  39.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total=  52.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=200, total=  52.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=250, total= 1.1min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total= 1.3min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=300, total= 1.3min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total= 1.4min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=350, total= 1.5min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 1.6min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=400, total= 1.6min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 1.8min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=450, total= 1.8min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 1.9min\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), n_estimators=500, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 23.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=200,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), 'n_estimators': 150}\n",
      "0.719761904762\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    " 'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned AdaBoost\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.71      0.74       181\n",
      "          1       0.99      0.89      0.94       171\n",
      "          2       0.65      0.59      0.61       169\n",
      "          3       0.82      0.83      0.83       187\n",
      "          4       0.65      0.72      0.69       174\n",
      "          5       0.68      0.94      0.79       195\n",
      "          6       0.43      0.51      0.47       172\n",
      "          7       0.83      0.66      0.74       198\n",
      "          8       0.95      0.94      0.94       168\n",
      "          9       0.95      0.77      0.85       185\n",
      "\n",
      "avg / total       0.78      0.76      0.76      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>163</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>188</td>\n",
       "      <td>193</td>\n",
       "      <td>269</td>\n",
       "      <td>206</td>\n",
       "      <td>158</td>\n",
       "      <td>167</td>\n",
       "      <td>150</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          128    1    3    8    0    0   39    0    2    0   181\n",
       "1            2  152    1   13    0    0    3    0    0    0   171\n",
       "2            0    0   99    0   31    0   39    0    0    0   169\n",
       "3            8    0    1  155   11    0   12    0    0    0   187\n",
       "4            0    0   24    4  126    0   18    0    2    0   174\n",
       "5            0    0    0    0    0  184    0    9    1    1   195\n",
       "6           25    0   24    7   25    0   88    0    3    0   172\n",
       "7            0    0    0    0    0   61    0  131    0    6   198\n",
       "8            0    0    1    1    0    1    7    0  158    0   168\n",
       "9            0    0    0    0    0   23    0   18    1  143   185\n",
       "All        163  153  153  188  193  269  206  158  167  150  1800"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with logistic regression\n",
    "my_model = linear_model.LogisticRegression()\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.801666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.76      0.75       141\n",
      "          1       0.96      0.91      0.94       111\n",
      "          2       0.77      0.76      0.76       141\n",
      "          3       0.81      0.87      0.84       106\n",
      "          4       0.66      0.73      0.70       116\n",
      "          5       0.91      0.79      0.84       117\n",
      "          6       0.57      0.50      0.53       128\n",
      "          7       0.86      0.86      0.86       113\n",
      "          8       0.91      0.94      0.93       124\n",
      "          9       0.86      0.97      0.91       103\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>144</td>\n",
       "      <td>105</td>\n",
       "      <td>139</td>\n",
       "      <td>113</td>\n",
       "      <td>128</td>\n",
       "      <td>101</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>128</td>\n",
       "      <td>116</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          107    2    3    8    1    0   18    0    2    0   141\n",
       "1            0  101    3    5    1    0    0    0    0    1   111\n",
       "2            2    0  107    0   20    0   10    0    2    0   141\n",
       "3            3    2    2   92    3    0    3    0    1    0   106\n",
       "4            1    0   10    4   85    0   15    0    1    0   116\n",
       "5            2    0    0    1    0   92    2   13    0    7   117\n",
       "6           28    0   12    1   18    0   64    0    5    0   128\n",
       "7            0    0    0    0    0    8    0   97    0    8   113\n",
       "8            1    0    2    2    0    1    1    0  117    0   124\n",
       "9            0    0    0    0    0    0    0    3    0  100   103\n",
       "All        144  105  139  113  128  101  113  113  128  116  1200"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.5s\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.5s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.8s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.8s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   1.9s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.0s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.0s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.0s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.1s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.1s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.3s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.2s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.4s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.3s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.4s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.3s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.5s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.4s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.5s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   42.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 0.4, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
      "0.818095238095\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Logistic Regression\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.82      0.81       181\n",
      "          1       0.96      0.96      0.96       171\n",
      "          2       0.73      0.72      0.73       169\n",
      "          3       0.83      0.83      0.83       187\n",
      "          4       0.74      0.77      0.76       174\n",
      "          5       0.94      0.92      0.93       195\n",
      "          6       0.63      0.59      0.61       172\n",
      "          7       0.94      0.93      0.94       198\n",
      "          8       0.91      0.94      0.92       168\n",
      "          9       0.93      0.95      0.94       185\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>184</td>\n",
       "      <td>172</td>\n",
       "      <td>166</td>\n",
       "      <td>186</td>\n",
       "      <td>180</td>\n",
       "      <td>191</td>\n",
       "      <td>161</td>\n",
       "      <td>197</td>\n",
       "      <td>174</td>\n",
       "      <td>189</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          148    1    4    8    1    0   16    0    3    0   181\n",
       "1            1  165    0    3    1    0    1    0    0    0   171\n",
       "2            0    1  122    0   25    0   19    0    2    0   169\n",
       "3           11    5    2  155    8    0    6    0    0    0   187\n",
       "4            0    0   16    5  134    1   16    0    2    0   174\n",
       "5            0    0    1    1    0  179    0    6    2    6   195\n",
       "6           24    0   18   10    9    2  102    0    7    0   172\n",
       "7            0    0    0    0    0    6    0  185    0    7   198\n",
       "8            0    0    3    4    2    0    1    0  158    0   168\n",
       "9            0    0    0    0    0    3    0    6    0  176   185\n",
       "All        184  172  166  186  180  191  161  197  174  189  1800"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.82      0.78       141\n",
      "          1       0.97      0.91      0.94       111\n",
      "          2       0.70      0.71      0.70       141\n",
      "          3       0.83      0.86      0.84       106\n",
      "          4       0.66      0.62      0.64       116\n",
      "          5       1.00      0.50      0.66       117\n",
      "          6       0.47      0.48      0.48       128\n",
      "          7       0.72      0.92      0.81       113\n",
      "          8       0.97      0.90      0.93       124\n",
      "          9       0.76      0.93      0.84       103\n",
      "\n",
      "avg / total       0.78      0.76      0.76      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>158</td>\n",
       "      <td>104</td>\n",
       "      <td>143</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>131</td>\n",
       "      <td>145</td>\n",
       "      <td>116</td>\n",
       "      <td>126</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4   5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          116    0    4    4    0   0   17    0    0    0   141\n",
       "1            1  101    1    5    1   0    2    0    0    0   111\n",
       "2            1    0  100    1   17   0   21    0    1    0   141\n",
       "3            4    2    2   91    5   0    2    0    0    0   106\n",
       "4            1    1   18    4   72   0   20    0    0    0   116\n",
       "5            1    0    0    1    0  58    2   33    1   21   117\n",
       "6           33    0   15    2   14   0   62    0    2    0   128\n",
       "7            0    0    0    0    0   0    0  104    0    9   113\n",
       "8            0    0    3    2    0   0    5    2  112    0   124\n",
       "9            1    0    0    0    0   0    0    6    0   96   103\n",
       "All        158  104  143  110  109  58  131  145  116  126  1200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   7.2s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   7.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   7.0s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   7.0s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   7.6s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   7.4s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   7.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   7.3s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   7.1s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   7.4s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   6.9s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   7.0s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   6.9s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   7.5s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   7.2s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   7.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   7.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   7.4s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   7.8s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   7.2s\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n",
      "0.767857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  4.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned kNN\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.82      0.75       181\n",
      "          1       0.98      0.96      0.97       171\n",
      "          2       0.73      0.73      0.73       169\n",
      "          3       0.86      0.79      0.82       187\n",
      "          4       0.70      0.72      0.71       174\n",
      "          5       1.00      0.75      0.86       195\n",
      "          6       0.49      0.44      0.46       172\n",
      "          7       0.82      0.95      0.88       198\n",
      "          8       0.96      0.93      0.94       168\n",
      "          9       0.90      0.96      0.93       185\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>218</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>173</td>\n",
       "      <td>180</td>\n",
       "      <td>147</td>\n",
       "      <td>153</td>\n",
       "      <td>230</td>\n",
       "      <td>163</td>\n",
       "      <td>198</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          149    1    4   11    1    0   13    0    2    0   181\n",
       "1            2  165    0    1    0    0    3    0    0    0   171\n",
       "2            2    0  124    1   17    0   25    0    0    0   169\n",
       "3           19    2    1  148    8    0    9    0    0    0   187\n",
       "4            1    0   15    7  126    0   23    0    2    0   174\n",
       "5            1    0    2    0    0  147    1   34    0   10   195\n",
       "6           44    0   21    4   25    0   75    0    3    0   172\n",
       "7            0    0    0    0    0    0    0  188    0   10   198\n",
       "8            0    0    3    1    3    0    4    1  156    0   168\n",
       "9            0    0    0    0    0    0    0    7    0  178   185\n",
       "All        218  168  170  173  180  147  153  230  163  198  1800"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(300, 100))\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.831666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.81      0.81       141\n",
      "          1       0.96      0.94      0.95       111\n",
      "          2       0.85      0.73      0.79       141\n",
      "          3       0.85      0.88      0.86       106\n",
      "          4       0.73      0.67      0.70       116\n",
      "          5       0.92      0.87      0.89       117\n",
      "          6       0.57      0.68      0.62       128\n",
      "          7       0.88      0.90      0.89       113\n",
      "          8       0.94      0.94      0.94       124\n",
      "          9       0.91      0.95      0.93       103\n",
      "\n",
      "avg / total       0.84      0.83      0.83      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>142</td>\n",
       "      <td>108</td>\n",
       "      <td>121</td>\n",
       "      <td>110</td>\n",
       "      <td>107</td>\n",
       "      <td>111</td>\n",
       "      <td>153</td>\n",
       "      <td>116</td>\n",
       "      <td>124</td>\n",
       "      <td>108</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          114    1    0    4    0    1   20    0    1    0   141\n",
       "1            1  104    1    4    0    0    1    0    0    0   111\n",
       "2            4    0  103    1   18    0   15    0    0    0   141\n",
       "3            2    3    0   93    2    1    5    0    0    0   106\n",
       "4            1    0   11    5   78    0   20    0    1    0   116\n",
       "5            1    0    0    0    0  102    0    9    0    5   117\n",
       "6           19    0    6    2    9    0   87    0    5    0   128\n",
       "7            0    0    0    0    0    6    0  102    0    5   113\n",
       "8            0    0    0    1    0    1    5    0  117    0   124\n",
       "9            0    0    0    0    0    0    0    5    0   98   103\n",
       "All        142  108  121  110  107  111  153  116  124  108  1200"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   4.1s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   3.7s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   5.2s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   5.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=   5.8s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=   5.9s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=  10.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   6.8s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=   5.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=   4.6s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=   5.0s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=   6.8s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   6.4s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   6.1s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=   4.8s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=   3.7s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=   4.8s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=   8.4s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   8.4s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   2.4s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=   3.3s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=   5.2s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=   3.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=   7.6s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   6.8s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   4.5s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=   4.2s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=   5.5s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=   3.9s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=   6.5s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   7.1s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   5.5s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=   6.4s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=   6.8s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=   6.0s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1.0000000000000001e-05, 'hidden_layer_sizes': 400}\n",
      "0.836666666667\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neural_network.MLPClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned MLP\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.867777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.85      0.84       181\n",
      "          1       0.95      0.98      0.97       171\n",
      "          2       0.83      0.67      0.75       169\n",
      "          3       0.89      0.78      0.83       187\n",
      "          4       0.74      0.83      0.78       174\n",
      "          5       0.96      0.94      0.95       195\n",
      "          6       0.63      0.74      0.68       172\n",
      "          7       0.95      0.94      0.95       198\n",
      "          8       0.96      0.96      0.96       168\n",
      "          9       0.95      0.96      0.95       185\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>184</td>\n",
       "      <td>175</td>\n",
       "      <td>137</td>\n",
       "      <td>164</td>\n",
       "      <td>194</td>\n",
       "      <td>192</td>\n",
       "      <td>201</td>\n",
       "      <td>197</td>\n",
       "      <td>168</td>\n",
       "      <td>188</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          154    0    3    3    1    0   20    0    0    0   181\n",
       "1            1  167    0    1    0    0    2    0    0    0   171\n",
       "2            1    1  114    2   28    0   23    0    0    0   169\n",
       "3           11    7    2  146   11    0   10    0    0    0   187\n",
       "4            0    0    5    4  144    1   18    0    2    0   174\n",
       "5            0    0    0    1    0  184    0    4    1    5   195\n",
       "6           17    0   11    6    7    0  127    0    4    0   172\n",
       "7            0    0    0    0    0    6    0  187    0    5   198\n",
       "8            0    0    2    1    3    0    1    0  161    0   168\n",
       "9            0    0    0    0    0    1    0    6    0  178   185\n",
       "All        184  175  137  164  194  192  201  197  168  188  1800"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Better Tree': 0.69555555555555559,\n",
       " 'Simple Tree': 0.73944444444444446,\n",
       " 'Tuned AdaBoost': 0.75777777777777777,\n",
       " 'Tuned Bagging': 0.69222222222222218,\n",
       " 'Tuned Logistic Regression': 0.84666666666666668,\n",
       " 'Tuned MLP': 0.86777777777777776,\n",
       " 'Tuned Random Forest': 0.80222222222222217,\n",
       " 'Tuned Tree': 0.68999999999999995,\n",
       " 'Tuned kNN': 0.80888888888888888}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_test_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAD8CAYAAABevCxMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134c9a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': 0.61333333333333329,\n",
       " 'Bagging': 0.72416666666666663,\n",
       " 'Better Tree': 0.67166666666666663,\n",
       " 'Logistic Regression': 0.80166666666666664,\n",
       " 'MLP': 0.83166666666666667,\n",
       " 'Random Forest': 0.72333333333333338,\n",
       " 'Simple Tree': 0.70166666666666666,\n",
       " 'kNN': 0.76000000000000001}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_valid_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAD8CAYAAAD61pSfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134e82dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tuned AdaBoost': {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=200,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'n_estimators': 150},\n",
       " 'Tuned Bagging': {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=200,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'n_estimators': 300},\n",
       " 'Tuned Logistic Regression': {'C': 0.4,\n",
       "  'max_iter': 1000,\n",
       "  'multi_class': 'ovr',\n",
       "  'solver': 'liblinear'},\n",
       " 'Tuned MLP': {'alpha': 1.0000000000000001e-05, 'hidden_layer_sizes': 400},\n",
       " 'Tuned Random Forest': {'max_features': 8,\n",
       "  'min_samples_split': 200,\n",
       "  'n_estimators': 450},\n",
       " 'Tuned Tree': {'criterion': 'gini',\n",
       "  'max_depth': 27,\n",
       "  'min_samples_split': 200},\n",
       " 'Tuned kNN': {'n_neighbors': 6}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_tuned_params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Best Model On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = linear_model.LogisticRegression(C=0.4,max_iter = 1000,multi_class='ovr',solver='liblinear')\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8597\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.82      0.82      1000\n",
      "          1       0.97      0.98      0.97      1000\n",
      "          2       0.84      0.72      0.77      1000\n",
      "          3       0.91      0.84      0.87      1000\n",
      "          4       0.76      0.82      0.79      1000\n",
      "          5       0.95      0.89      0.92      1000\n",
      "          6       0.63      0.70      0.67      1000\n",
      "          7       0.90      0.92      0.91      1000\n",
      "          8       0.94      0.96      0.95      1000\n",
      "          9       0.91      0.95      0.93      1000\n",
      "\n",
      "avg / total       0.86      0.86      0.86     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>818</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>716</td>\n",
       "      <td>9</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>843</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>821</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>129</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>704</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>957</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>951</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>995</td>\n",
       "      <td>1011</td>\n",
       "      <td>852</td>\n",
       "      <td>929</td>\n",
       "      <td>1077</td>\n",
       "      <td>941</td>\n",
       "      <td>1115</td>\n",
       "      <td>1020</td>\n",
       "      <td>1016</td>\n",
       "      <td>1044</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0     1    2    3     4    5     6     7     8     9    All\n",
       "True                                                                    \n",
       "0          818     4   15   22     0    1   123     0    16     1   1000\n",
       "1            3   978    0   10     2    1     6     0     0     0   1000\n",
       "2           12     0  716    9   138    0   114     0    11     0   1000\n",
       "3           27    25   13  843    40    0    48     0     4     0   1000\n",
       "4            1     0   43   28   821    0   103     0     4     0   1000\n",
       "5            2     1    0    0     0  894     0    57     8    38   1000\n",
       "6          129     3   60   14    74    0   704     0    15     1   1000\n",
       "7            0     0    0    0     0   33     0   915     0    52   1000\n",
       "8            3     0    5    3     2    5    17     7   957     1   1000\n",
       "9            0     0    0    0     0    7     0    41     1   951   1000\n",
       "All        995  1011  852  929  1077  941  1115  1020  1016  1044  10000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
